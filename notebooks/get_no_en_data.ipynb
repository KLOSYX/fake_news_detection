{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import langdetect\n",
    "import pandas as pd\n",
    "from pyrootutils import setup_root\n",
    "from tqdm import tqdm\n",
    "\n",
    "root = setup_root(\".\", pythonpath=True)\n",
    "\n",
    "langdetect.DetectorFactory.seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = pd.read_csv(\n",
    "    root / \"data/image-verification-corpus-master/mediaeval2015/devset/tweets.txt\",\n",
    "    delimiter=\"\\t\",\n",
    ")\n",
    "\n",
    "# %%\n",
    "test_data = pd.read_csv(\n",
    "    root / \"data/image-verification-corpus-master/mediaeval2015/testset/tweets.txt\",\n",
    "    delimiter=\"\\t\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([dev_data, test_data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    try:\n",
    "        text = text.decode(\"utf-8\").lower()\n",
    "    except Exception as ex:\n",
    "        text = text.encode(\"utf-8\").decode(\"utf-8\").lower()\n",
    "    text = re.sub(\"\\u2019|\\u2018\", \"'\", text)\n",
    "    text = re.sub(\"\\u201c|\\u201d\", '\"', text)\n",
    "    text = re.sub(\"[\\u2000-\\u206F]\", \" \", text)\n",
    "    text = re.sub(\"[\\u20A0-\\u20CF]\", \" \", text)\n",
    "    text = re.sub(\"[\\u2100-\\u214F]\", \" \", text)\n",
    "    text = re.sub(r\"http:\\ \", \"http:\", text)\n",
    "    text = re.sub(r\"http[s]?:[^\\ ]+\", \" \", text)\n",
    "    text = re.sub(r\"&gt;\", \" \", text)\n",
    "    text = re.sub(r\"&lt;\", \" \", text)\n",
    "    text = re.sub(r\"&quot;\", \" \", text)\n",
    "    text = re.sub(r\"\\\"\", \" \", text)\n",
    "    text = re.sub(r\"#\\ \", \"#\", text)\n",
    "    text = re.sub(r\"\\\\n\", \" \", text)\n",
    "    text = re.sub(r\"\\\\\", \" \", text)\n",
    "    text = re.sub(r\"[\\(\\)\\[\\]\\{\\}]\", r\" \", text)\n",
    "    text = re.sub(\n",
    "        \"[\" \"\\U0001F300-\\U0001F64F\" \"\\U0001F680-\\U0001F6FF\" \"\\u2600-\\u26FF\\u2700-\\u27BF]+\",\n",
    "        r\" \",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(r\"\\'s\", \" is \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" had \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"#\", \" #\", text)\n",
    "    text = re.sub(r\"@\", \" @\", text)\n",
    "    text = re.sub(r\"[\\!\\?\\.\\,\\+\\-\\$\\%\\^\\>\\<\\=\\:\\;\\*\\(\\)\\{\\}\\[\\]\\/\\~\\&\\'\\|]\", \" \", text)\n",
    "    text = text.strip()\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_lang(text: str):\n",
    "    try:\n",
    "        lang = langdetect.detect(text)\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"text: {text}\")\n",
    "        tqdm.write(str(e))\n",
    "        lang = \"unk\"\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas(desc=\"Detecting language\")\n",
    "\n",
    "all_data[\"text\"] = all_data.tweetText.progress_apply(clean_text)\n",
    "all_data[\"lang\"] = all_data.text.progress_apply(detection_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.tweetId[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[all_data.lang != \"en\"][[\"tweetId\", \"text\"]].to_excel(\"all_data.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[all_data.lang != \"en\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.google_trans_new.google_trans_new import google_translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = google_translator(\n",
    "    proxies={\"https\": \"172.22.112.1:7890\"},\n",
    "    timeout=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "from httpcore import SyncHTTPProxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator(proxies={\"http\": SyncHTTPProxy((b\"http\", b\"172.22.112.1\", 7890, b\"\"))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import random\n",
    "from hashlib import md5\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "class BaiDuFanyi:\n",
    "    def __init__(self, appKey, appSecret):\n",
    "        self.url = \"https://fanyi-api.baidu.com/api/trans/vip/translate\"\n",
    "        self.appid = appKey\n",
    "        self.secretKey = appSecret\n",
    "        self.fromLang = \"auto\"\n",
    "        self.toLang = \"en\"\n",
    "        self.salt = random.randint(32768, 65536)\n",
    "        self.header = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "\n",
    "    def BdTrans(self, text):\n",
    "        sign = self.appid + text + str(self.salt) + self.secretKey\n",
    "        md = hashlib.md5()\n",
    "        md.update(sign.encode(encoding=\"utf-8\"))\n",
    "        sign = md.hexdigest()\n",
    "        data = {\n",
    "            \"appid\": self.appid,\n",
    "            \"q\": text,\n",
    "            \"from\": self.fromLang,\n",
    "            \"to\": self.toLang,\n",
    "            \"salt\": self.salt,\n",
    "            \"sign\": sign,\n",
    "        }\n",
    "        response = requests.post(self.url, params=data, headers=self.header)  # 发送post请求\n",
    "        text = response.json()  # 返回的为json格式用json接收数据\n",
    "        # print(text)\n",
    "        try:\n",
    "            results = text[\"trans_result\"][0][\"dst\"]\n",
    "        except Exception:\n",
    "            results = \"\"\n",
    "        return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    appKey = \"20221012001387816\"  # 你在第一步申请的APP ID\n",
    "    appSecret = \"ThXoAK3TTPMmnaOKX0yF\"  # 公钥\n",
    "    BaiduTranslate_test = BaiDuFanyi(appKey, appSecret)\n",
    "    Results = BaiduTranslate_test.BdTrans(\"Hello, World!\")  # 要翻译的词组\n",
    "    print(Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = BaiDuFanyi(appKey, appSecret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator.BdTrans(\"你好，世界！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_en_data = all_data[all_data.lang != \"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_en_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas(desc=\"Translating\")\n",
    "\n",
    "non_en_data[\"translated_text\"] = non_en_data.text.progress_apply(translator.BdTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.merge(non_en_data[[\"tweetId\", \"translated_text\"]], on=\"tweetId\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_en_data[[\"tweetId\", \"text\", \"translated_text\"]].to_csv(\"translated_text_map.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_dict = {\n",
    "    str(k): v\n",
    "    for (k, v) in non_en_data[[\"tweetId\", \"translated_text\"]].itertuples(index=False, name=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(translated_dict, open(\"translated_text_map.json\", \"w\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('fake_news_detection')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a289c90f01c4539891e961280e81b0f3dd3c992399cf7e9c131c6d3a4abe927d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
