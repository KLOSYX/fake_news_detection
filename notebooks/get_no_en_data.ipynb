{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langdetect\n",
    "import pandas as pd\n",
    "from pyrootutils import setup_root\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "root = setup_root(\".\", pythonpath=True)\n",
    "\n",
    "langdetect.DetectorFactory.seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = pd.read_csv(\n",
    "    root / \"data/image-verification-corpus-master/mediaeval2015/devset/tweets.txt\",\n",
    "    delimiter=\"\\t\",\n",
    ")\n",
    "\n",
    "# %%\n",
    "test_data = pd.read_csv(\n",
    "    root / \"data/image-verification-corpus-master/mediaeval2015/testset/tweets.txt\",\n",
    "    delimiter=\"\\t\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([dev_data, test_data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    try:\n",
    "        text = text.decode(\"utf-8\").lower()\n",
    "    except Exception as ex:\n",
    "        text = text.encode(\"utf-8\").decode(\"utf-8\").lower()\n",
    "    text = re.sub(\"\\u2019|\\u2018\", \"'\", text)\n",
    "    text = re.sub(\"\\u201c|\\u201d\", '\"', text)\n",
    "    text = re.sub(\"[\\u2000-\\u206F]\", \" \", text)\n",
    "    text = re.sub(\"[\\u20A0-\\u20CF]\", \" \", text)\n",
    "    text = re.sub(\"[\\u2100-\\u214F]\", \" \", text)\n",
    "    text = re.sub(r\"http:\\ \", \"http:\", text)\n",
    "    text = re.sub(r\"http[s]?:[^\\ ]+\", \" \", text)\n",
    "    text = re.sub(r\"&gt;\", \" \", text)\n",
    "    text = re.sub(r\"&lt;\", \" \", text)\n",
    "    text = re.sub(r\"&quot;\", \" \", text)\n",
    "    text = re.sub(r\"\\\"\", \" \", text)\n",
    "    text = re.sub(r\"#\\ \", \"#\", text)\n",
    "    text = re.sub(r\"\\\\n\", \" \", text)\n",
    "    text = re.sub(r\"\\\\\", \" \", text)\n",
    "    text = re.sub(r\"[\\(\\)\\[\\]\\{\\}]\", r\" \", text)\n",
    "    text = re.sub(\n",
    "        \"[\" \"\\U0001F300-\\U0001F64F\" \"\\U0001F680-\\U0001F6FF\" \"\\u2600-\\u26FF\\u2700-\\u27BF]+\",\n",
    "        r\" \",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(r\"\\'s\", \" is \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" had \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"#\", \" #\", text)\n",
    "    text = re.sub(r\"@\", \" @\", text)\n",
    "    text = re.sub(r\"[\\!\\?\\.\\,\\+\\-\\$\\%\\^\\>\\<\\=\\:\\;\\*\\(\\)\\{\\}\\[\\]\\/\\~\\&\\'\\|]\", \" \", text)\n",
    "    text = text.strip()\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_lang(text: str):\n",
    "    try:\n",
    "        lang = langdetect.detect(text)\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"text: {text}\")\n",
    "        tqdm.write(str(e))\n",
    "        lang = \"unk\"\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting language: 100%|██████████| 18032/18032 [00:00<00:00, 28069.04it/s]\n",
      "Detecting language:  67%|██████▋   | 12014/18032 [01:12<00:36, 166.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: \n",
      "No features in text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting language: 100%|██████████| 18032/18032 [01:42<00:00, 176.68it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc=\"Detecting language\")\n",
    "\n",
    "all_data[\"text\"] = all_data.tweetText.progress_apply(clean_text)\n",
    "all_data[\"lang\"] = all_data.text.progress_apply(detection_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    263046056240115712\n",
       "0    578854927457349632\n",
       "Name: tweetId, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.tweetId[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[all_data.lang != \"en\"][[\"tweetId\", \"text\"]].to_excel(\"all_data.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetId</th>\n",
       "      <th>tweetText</th>\n",
       "      <th>userId</th>\n",
       "      <th>imageId(s)</th>\n",
       "      <th>username</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>263046056240115712</td>\n",
       "      <td>¿Se acuerdan de la película: “El día después d...</td>\n",
       "      <td>21226711</td>\n",
       "      <td>sandyA_fake_46</td>\n",
       "      <td>iAnnieM</td>\n",
       "      <td>Mon Oct 29 22:34:01 +0000 2012</td>\n",
       "      <td>fake</td>\n",
       "      <td>es</td>\n",
       "      <td>¿se acuerdan de la película el día después de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>262995061304852481</td>\n",
       "      <td>@milenagimon: Miren a Sandy en NY!  Tremenda i...</td>\n",
       "      <td>192378571</td>\n",
       "      <td>sandyA_fake_09</td>\n",
       "      <td>CarlosVerareal</td>\n",
       "      <td>Mon Oct 29 19:11:23 +0000 2012</td>\n",
       "      <td>fake</td>\n",
       "      <td>es</td>\n",
       "      <td>@milenagimon miren a sandy en ny tremenda imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262979898002534400</td>\n",
       "      <td>Buena la foto del Huracán Sandy, me recuerda a...</td>\n",
       "      <td>132303095</td>\n",
       "      <td>sandyA_fake_09</td>\n",
       "      <td>LucasPalape</td>\n",
       "      <td>Mon Oct 29 18:11:08 +0000 2012</td>\n",
       "      <td>fake</td>\n",
       "      <td>es</td>\n",
       "      <td>buena la foto del huracán sandy me recuerda a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>262990978611286016</td>\n",
       "      <td>Good luck #ny #newyork #usa #hurricane #sandy ...</td>\n",
       "      <td>125724906</td>\n",
       "      <td>sandyA_fake_29</td>\n",
       "      <td>gsevigny</td>\n",
       "      <td>Mon Oct 29 18:55:10 +0000 2012</td>\n",
       "      <td>fake</td>\n",
       "      <td>cy</td>\n",
       "      <td>good luck #ny #newyork #usa #hurricane #sandy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>263422787513901056</td>\n",
       "      <td>Mans best friend #love #hurricane #sandy #dog ...</td>\n",
       "      <td>174085679</td>\n",
       "      <td>sandyA_fake_21</td>\n",
       "      <td>CafeBustelo711</td>\n",
       "      <td>Tue Oct 30 23:31:01 +0000 2012</td>\n",
       "      <td>fake</td>\n",
       "      <td>da</td>\n",
       "      <td>mans best friend #love #hurricane #sandy #dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>263019769895190528</td>\n",
       "      <td>Que Deus proteja o Soho, a All Saints e a XL !...</td>\n",
       "      <td>83630316</td>\n",
       "      <td>sandyA_fake_09</td>\n",
       "      <td>nilmar</td>\n",
       "      <td>Mon Oct 29 20:49:34 +0000 2012</td>\n",
       "      <td>fake</td>\n",
       "      <td>ca</td>\n",
       "      <td>que deus proteja o soho a all saints e a xl #s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>263276356165586944</td>\n",
       "      <td>#sandy #hurricane #fun #usa http://t.co/I61JSFID</td>\n",
       "      <td>86832033</td>\n",
       "      <td>sandyA_fake_47</td>\n",
       "      <td>hakosanart</td>\n",
       "      <td>Tue Oct 30 13:49:09 +0000 2012</td>\n",
       "      <td>fake</td>\n",
       "      <td>es</td>\n",
       "      <td>#sandy #hurricane #fun #usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>263142454511951873</td>\n",
       "      <td>Акула на шоссейной магистрали \\n#hurricane #sa...</td>\n",
       "      <td>376885703</td>\n",
       "      <td>sandyA_fake_05</td>\n",
       "      <td>policy_by</td>\n",
       "      <td>Tue Oct 30 04:57:04 +0000 2012</td>\n",
       "      <td>fake</td>\n",
       "      <td>bg</td>\n",
       "      <td>акула на шоссейной магистрали #hurricane #sandy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>263107559597146112</td>\n",
       "      <td>Nunca imaginei imaginar essa cena na vida real...</td>\n",
       "      <td>24748643</td>\n",
       "      <td>sandyA_fake_17</td>\n",
       "      <td>lyviagamerco</td>\n",
       "      <td>Tue Oct 30 02:38:25 +0000 2012</td>\n",
       "      <td>fake</td>\n",
       "      <td>it</td>\n",
       "      <td>nunca imaginei imaginar essa cena na vida real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>263009179613134848</td>\n",
       "      <td>Holy frankenstorm! #newyork #frankenstorm #hur...</td>\n",
       "      <td>327202954</td>\n",
       "      <td>sandyA_fake_34</td>\n",
       "      <td>maddieg_rae</td>\n",
       "      <td>Mon Oct 29 20:07:29 +0000 2012</td>\n",
       "      <td>fake</td>\n",
       "      <td>no</td>\n",
       "      <td>holy frankenstorm #newyork #frankenstorm #hurr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweetId                                          tweetText  \\\n",
       "0    263046056240115712  ¿Se acuerdan de la película: “El día después d...   \n",
       "1    262995061304852481  @milenagimon: Miren a Sandy en NY!  Tremenda i...   \n",
       "2    262979898002534400  Buena la foto del Huracán Sandy, me recuerda a...   \n",
       "13   262990978611286016  Good luck #ny #newyork #usa #hurricane #sandy ...   \n",
       "35   263422787513901056  Mans best friend #love #hurricane #sandy #dog ...   \n",
       "66   263019769895190528  Que Deus proteja o Soho, a All Saints e a XL !...   \n",
       "67   263276356165586944   #sandy #hurricane #fun #usa http://t.co/I61JSFID   \n",
       "149  263142454511951873  Акула на шоссейной магистрали \\n#hurricane #sa...   \n",
       "179  263107559597146112  Nunca imaginei imaginar essa cena na vida real...   \n",
       "222  263009179613134848  Holy frankenstorm! #newyork #frankenstorm #hur...   \n",
       "\n",
       "        userId      imageId(s)        username  \\\n",
       "0     21226711  sandyA_fake_46         iAnnieM   \n",
       "1    192378571  sandyA_fake_09  CarlosVerareal   \n",
       "2    132303095  sandyA_fake_09     LucasPalape   \n",
       "13   125724906  sandyA_fake_29        gsevigny   \n",
       "35   174085679  sandyA_fake_21  CafeBustelo711   \n",
       "66    83630316  sandyA_fake_09          nilmar   \n",
       "67    86832033  sandyA_fake_47      hakosanart   \n",
       "149  376885703  sandyA_fake_05       policy_by   \n",
       "179   24748643  sandyA_fake_17    lyviagamerco   \n",
       "222  327202954  sandyA_fake_34     maddieg_rae   \n",
       "\n",
       "                          timestamp label lang  \\\n",
       "0    Mon Oct 29 22:34:01 +0000 2012  fake   es   \n",
       "1    Mon Oct 29 19:11:23 +0000 2012  fake   es   \n",
       "2    Mon Oct 29 18:11:08 +0000 2012  fake   es   \n",
       "13   Mon Oct 29 18:55:10 +0000 2012  fake   cy   \n",
       "35   Tue Oct 30 23:31:01 +0000 2012  fake   da   \n",
       "66   Mon Oct 29 20:49:34 +0000 2012  fake   ca   \n",
       "67   Tue Oct 30 13:49:09 +0000 2012  fake   es   \n",
       "149  Tue Oct 30 04:57:04 +0000 2012  fake   bg   \n",
       "179  Tue Oct 30 02:38:25 +0000 2012  fake   it   \n",
       "222  Mon Oct 29 20:07:29 +0000 2012  fake   no   \n",
       "\n",
       "                                                  text  \n",
       "0    ¿se acuerdan de la película el día después de ...  \n",
       "1    @milenagimon miren a sandy en ny tremenda imag...  \n",
       "2    buena la foto del huracán sandy me recuerda a ...  \n",
       "13       good luck #ny #newyork #usa #hurricane #sandy  \n",
       "35       mans best friend #love #hurricane #sandy #dog  \n",
       "66   que deus proteja o soho a all saints e a xl #s...  \n",
       "67                         #sandy #hurricane #fun #usa  \n",
       "149    акула на шоссейной магистрали #hurricane #sandy  \n",
       "179  nunca imaginei imaginar essa cena na vida real...  \n",
       "222  holy frankenstorm #newyork #frankenstorm #hurr...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[all_data.lang != \"en\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.google_trans_new.google_trans_new import google_translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = google_translator(\n",
    "    proxies={\"https\": \"172.22.112.1:7890\"},\n",
    "    timeout=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "from httpcore import SyncHTTPProxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator(\n",
    "    proxies={\"http\": SyncHTTPProxy((b'http', b'172.22.112.1', 7890, b''))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import random\n",
    "import json\n",
    "import hashlib\n",
    "from hashlib import md5\n",
    "\n",
    "class BaiDuFanyi:\n",
    "    def __init__(self, appKey, appSecret):\n",
    "        self.url = 'https://fanyi-api.baidu.com/api/trans/vip/translate'\n",
    "        self.appid = appKey\n",
    "        self.secretKey = appSecret\n",
    "        self.fromLang = 'auto'\n",
    "        self.toLang = 'en'\n",
    "        self.salt = random.randint(32768,65536)\n",
    "        self.header = {'Content-Type': 'application/x-www-form-urlencoded'}\n",
    "    def BdTrans(self,text):\n",
    "        sign = self.appid + text + str(self.salt) + self.secretKey\n",
    "        md = hashlib.md5()\n",
    "        md.update(sign.encode(encoding='utf-8'))\n",
    "        sign =md.hexdigest()\n",
    "        data = {\n",
    "            \"appid\": self.appid,\n",
    "            \"q\": text,\n",
    "            \"from\": self.fromLang,\n",
    "            \"to\": self.toLang,\n",
    "            \"salt\": self.salt,\n",
    "            \"sign\": sign\n",
    "        }\n",
    "        response = requests.post(self.url, params=data, headers=self.header)  # 发送post请求\n",
    "        text = response.json()  # 返回的为json格式用json接收数据\n",
    "        # print(text)\n",
    "        try:\n",
    "            results = text['trans_result'][0]['dst']\n",
    "        except Exception:\n",
    "            results = \"\"\n",
    "        return results\n",
    "\n",
    "if __name__=='__main__':\n",
    "    appKey = '20221012001387816'   #你在第一步申请的APP ID\n",
    "    appSecret = 'ThXoAK3TTPMmnaOKX0yF' #公钥\n",
    "    BaiduTranslate_test = BaiDuFanyi(appKey,appSecret)\n",
    "    Results = BaiduTranslate_test.BdTrans(\"Hello, World!\")#要翻译的词组\n",
    "    print(Results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = BaiDuFanyi(appKey, appSecret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, World!'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator.BdTrans(\"你好，世界！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_en_data = all_data[all_data.lang != \"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4477, 9)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_en_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating: 100%|██████████| 4477/4477 [47:18<00:00,  1.58it/s] \n",
      "/tmp/ipykernel_25832/3324839375.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  non_en_data[\"translated_text\"] = non_en_data.text.progress_apply(translator.BdTrans)\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc=\"Translating\")\n",
    "\n",
    "non_en_data[\"translated_text\"] = non_en_data.text.progress_apply(translator.BdTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.merge(non_en_data[[\"tweetId\", \"translated_text\"]], on=\"tweetId\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_en_data[[\"tweetId\", \"text\", \"translated_text\"]].to_csv(\"translated_text_map.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_dict ={str(k): v for (k, v) in non_en_data[[\"tweetId\", \"translated_text\"]].itertuples(index=False, name=None)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json.dump(translated_dict, open(\"translated_text_map.json\", \"w\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('fake_news_detection')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a289c90f01c4539891e961280e81b0f3dd3c992399cf7e9c131c6d3a4abe927d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
